{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv\n",
    "#!pip install torch-geometric\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "temperature=350\n",
    "material='NiCoCr'\n",
    "train_temperature_list=[350,650,850,1150]\n",
    "test_temperature_list=[450,550,750,950,1050]\n",
    "temperature_list=train_temperature_list+test_temperature_list\n",
    "interval=200\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Wheather CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Node Feature Matrices and Edge Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "node_feature_list=[]\n",
    "dataloader_dict={}\n",
    "with open(\"config.yml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "graph_directory=config['directories']['graph_directory']\n",
    "lmp_file_directory=config['directories']['lmp_file_directory']\n",
    "\n",
    "\n",
    "\n",
    "for temperature in temperature_list:\n",
    "\n",
    "    node_feature=np.vstack([np.load(graph_directory+f'\\\\T={temperature}K\\\\feature.{temperature}K.{i}.npy') for i in range(interval, 60000 + 1, interval)])\n",
    "\n",
    "    node_feature_list.append(node_feature)\n",
    "\n",
    "all_node_features=np.vstack(node_feature_list)\n",
    "scaler.fit(all_node_features)\n",
    "graph_list=[]\n",
    "\n",
    "for temperature in temperature_list:\n",
    "\n",
    "    particular_graph_list=[]\n",
    "\n",
    "    label = np.genfromtxt(lmp_file_directory+f'\\\\T={temperature}K\\\\Potential Energy vs step T_{temperature}.txt')\n",
    "\n",
    "    for i in range(interval,60000+1,interval):\n",
    "\n",
    "        node_features = np.load(graph_directory+f'\\\\T={temperature}K\\\\feature.{temperature}K.{i}.npy')\n",
    " \n",
    "        node_features = scaler.transform(node_features)\n",
    "        edge_indices = np.load(graph_directory+f'\\\\T={temperature}K\\\\edge.{temperature}K.{i}.npy').transpose()\n",
    "        #edge_indices = np.concatenate((edge_indices, np.flip(edge_indices, axis=0)), axis=1)\n",
    "        #adding self loops\n",
    "        self_loop=np.arange(0, 13500).reshape(1, -1)\n",
    "        self_loop_add=np.concatenate((self_loop,self_loop),axis=0)\n",
    "        # print(self_loop.shape,self_loop_add.shape)\n",
    "        edge_indices=np.concatenate((edge_indices,self_loop_add),axis=1)\n",
    "        \n",
    "\n",
    "        graph_label = torch.tensor(label[i, 1] / 13500, dtype=torch.float)\n",
    "\n",
    "        node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "        edge_indices = torch.tensor(edge_indices, dtype=torch.long)\n",
    "        \n",
    "        graph = Data(x=node_features, edge_index=edge_indices, y=graph_label)\n",
    "        graph.graph_name = i\n",
    "        if temperature in train_temperature_list:\n",
    "            graph_list.append(graph) # Only the graphs of training annealing temperatures are appened\n",
    "        particular_graph_list.append(graph) \n",
    "        \n",
    "    var=DataLoader(particular_graph_list)\n",
    "\n",
    "    dataloader_dict[temperature]=var # Graphs of a particular annealing temperature are stored\n",
    "\n",
    "            \n",
    "print(graph_list[0].x.shape, graph_list[0].edge_index.shape)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(seed + worker_id)\n",
    "    random.seed(seed + worker_id)\n",
    "batch_size = 1\n",
    "loader = DataLoader(graph_list, batch_size=batch_size, shuffle=True,worker_init_fn=worker_init_fn)\n",
    "print(loader)\n",
    "print(dataloader_dict)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNModel(torch.nn.Module):\n",
    "    def __init__(self, in_channel, hidden_channel,hidden_layers):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channel, hidden_channel,aggr='sum')\n",
    "        self.hidden_conv=nn.ModuleList()\n",
    "        for _ in range (hidden_layers):\n",
    "            self.hidden_conv.append(GCNConv(hidden_channel,hidden_channel,aggr='sum'))\n",
    "        \n",
    "        self.conv4 = GCNConv(hidden_channel, 1,aggr='sum')\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(13500, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x=self.relu(self.conv1(x,edge_index))\n",
    "        x=self.dropout(x)\n",
    "        \n",
    "        for h in self.hidden_conv:\n",
    "            x=self.relu(h(x,edge_index))\n",
    "            x=self.dropout(x)\n",
    "            \n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = torch.squeeze(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch.x, batch.edge_index)\n",
    "        loss = criterion(output, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def predict(loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_names = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch.x, batch.edge_index)\n",
    "            all_preds.append(output.cpu())\n",
    "            all_labels.append(batch.y.cpu())\n",
    "            all_names.extend([int(name) for name in batch.graph_name])\n",
    "    return torch.cat(all_preds), torch.cat(all_labels), all_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channel = graph_list[0].x.shape[1]\n",
    "hidden_channel = 300  # Increased model complexity #previous 64\n",
    "epochs = 800 #previous 150\n",
    "lr = 0.0001  #lr =0.001 is used instead of 0.0005\n",
    "best_loss=1e3\n",
    "\n",
    "model = GCNModel(in_channel, hidden_channel,3).to(device)\n",
    "#model.apply(init_weights)  # Apply weight initialization\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "#scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "start_time = time.time()\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    loss = train()\n",
    "    #scheduler.step()\n",
    "    losses.append(loss)\n",
    "    if loss<best_loss:\n",
    "        best_epoch=epoch+1\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        best_loss=loss\n",
    "        print(f'Best epoch = {best_epoch}')\n",
    "    \n",
    "    print(f'Epoch = {epoch + 1}/{epochs} Loss = {loss}')\n",
    "    \n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time taken to run the code: {elapsed_time/60:.6f} minutes\")\n",
    "plt.plot(range(epochs), losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "'''\n",
    "preds, labels, names = predict(loader)\n",
    "\n",
    "\n",
    "preds = preds.numpy()\n",
    "labels = labels.numpy()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(names, labels, label='Actual')\n",
    "plt.plot(names, preds, label='Predicted', linestyle='dashed')\n",
    "plt.xlabel('Graph Index')\n",
    "plt.ylabel('Normalized Potential Energy')\n",
    "plt.title('Actual vs Predicted Potential Energy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Predictions on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def predict(loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_names = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            output = model(batch.x, batch.edge_index)\n",
    "            all_preds.append(output.cpu())\n",
    "            all_labels.append(batch.y.cpu())\n",
    "            all_names.extend([int(name) for name in batch.graph_name])\n",
    "    return torch.cat(all_preds), torch.cat(all_labels), all_names\n",
    "\n",
    "fig_1,axs_1=plt.subplots(1,len(train_temperature_list), figsize=(30,5))\n",
    "\n",
    "x=0\n",
    "\n",
    "for temperature in train_temperature_list:\n",
    "\n",
    "\n",
    "    loader_var=dataloader_dict[temperature]\n",
    "\n",
    "    preds, labels, names = predict(loader_var)\n",
    "\n",
    "\n",
    "    preds = preds.numpy()\n",
    "    labels = labels.numpy()\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "    'Index': names,\n",
    "    'Actual': labels,\n",
    "    'Predicted': preds\n",
    "    })\n",
    "\n",
    "\n",
    "    df = df.sort_values(by='Index')\n",
    "\n",
    "    df.to_csv(f'case_study_3_predictions_vs_actuals_train_{temperature}.csv', index=False)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    axs_1[x].plot(names, labels, label='Actual',marker='x')\n",
    "    axs_1[x].plot(names, preds, label='Predicted', marker='x')\n",
    "    axs_1[x].set_xlabel('MC steps')\n",
    "    axs_1[x].set_ylabel('Normalized Potential Energy')\n",
    "    axs_1[x].set_title(f'Actual vs Predicted Potential Energy {temperature}K')\n",
    "    axs_1[x].legend()\n",
    "\n",
    "   \n",
    "\n",
    "    x=x+1\n",
    "\n",
    "\n",
    "fig_1.suptitle('On Train Set', fontsize=16)\n",
    "fig_1.savefig('case_study_3_training performance_hidden_300_2nd_run.png',dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Predictions on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_2,axs_2=plt.subplots(1,len(test_temperature_list), figsize=(30,5))\n",
    "\n",
    "x=0\n",
    "\n",
    "for temperature in test_temperature_list:\n",
    "\n",
    "\n",
    "    loader_var=dataloader_dict[temperature]\n",
    "\n",
    "    preds, labels, names = predict(loader_var)\n",
    "\n",
    "\n",
    "    preds = preds.numpy()\n",
    "    labels = labels.numpy()\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "    'Index': names,\n",
    "    'Actual': labels,\n",
    "    'Predicted': preds\n",
    "    })\n",
    "\n",
    "\n",
    "    df = df.sort_values(by='Index')\n",
    "\n",
    "    df.to_csv(f'case_study_3_predictions_vs_actuals_test_{temperature}.csv', index=False)\n",
    "\n",
    "\n",
    "    \n",
    "    axs_2[x].plot(names, labels, label='Actual',marker='x')\n",
    "    axs_2[x].plot(names, preds, label='Predicted', marker='x')\n",
    "    axs_2[x].set_xlabel('MC Steps')\n",
    "    axs_2[x].set_ylabel('Normalized Potential Energy')\n",
    "    axs_2[x].set_title(f'Actual vs Predicted Potential Energy {temperature}K')\n",
    "    axs_2[x].legend()\n",
    "    fig_2.suptitle('On Test Set', fontsize=16)\n",
    "\n",
    "    x=x+1\n",
    "\n",
    "\n",
    "fig_2.savefig('case_study_3_testing performance_hidden_300_2nd_run.png',dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
